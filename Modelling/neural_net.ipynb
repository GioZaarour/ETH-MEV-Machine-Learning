{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/block_data_ready_cleaned.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "features = ['gas_used', 'base_fee_per_gas_in_eth', 'validator_is_registered_with_relay',\n",
    "            'is_fb_builder', 'sandwiches_count', 'liquidations_count',\n",
    "            'sandwiched_swaps_count', 'arbitrages_count', 'hour_of_day',\n",
    "            'block_fullness', 'total_gas_fees', 'base_fee_change_percentage',\n",
    "            'network_demand']\n",
    "target = 'proposer_total_reward_in_eth'\n",
    "\n",
    "# Prepare the data\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "#convert back to df\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reset indices to align training and test sets with their target values\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sample a smaller subset from the training and testing sets (e.g., 50%)\n",
    "sample_frac = 0.05\n",
    "X_train_small = X_train.sample(frac=sample_frac, random_state=42)\n",
    "y_train_small = y_train[X_train_small.index]\n",
    "X_test_small = X_test.sample(frac=sample_frac, random_state=42)\n",
    "y_test_small = y_test[X_test_small.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "12800/12800 [==============================] - 48s 4ms/step - loss: 2.4905 - val_loss: 0.3089\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 46s 4ms/step - loss: 2.4786 - val_loss: 0.3135\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 49s 4ms/step - loss: 2.4703 - val_loss: 0.3020\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 50s 4ms/step - loss: 2.4715 - val_loss: 0.3197\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 50s 4ms/step - loss: 2.4756 - val_loss: 0.3043\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 51s 4ms/step - loss: 2.4710 - val_loss: 0.3195\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 51s 4ms/step - loss: 2.4653 - val_loss: 0.3235\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 52s 4ms/step - loss: 2.4687 - val_loss: 0.3080\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 53s 4ms/step - loss: 2.4621 - val_loss: 0.3044\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 52s 4ms/step - loss: 2.4655 - val_loss: 0.3112\n",
      "4000/4000 [==============================] - 12s 3ms/step\n",
      "Basic Neural Network RMSE: 0.7258070051367116\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Basic Neural Network RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best parameters found:  {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (5,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "MLP RMSE on Test Set: 0.33876124038017336\n"
     ]
    }
   ],
   "source": [
    "# Now try an MLPRegressor\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(5,), (7, 7)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "mlp = MLPRegressor(random_state=42, max_iter=10000)\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, n_jobs=6, cv=3, scoring='neg_mean_squared_error', verbose=3)\n",
    "grid_search.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Prediction with the best found parameters\n",
    "y_pred = grid_search.predict(X_test_small)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = sqrt(mean_squared_error(y_test_small, y_pred))\n",
    "print(f'MLP RMSE on Test Set: {rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
