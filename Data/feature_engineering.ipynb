{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the block data from the Flashbots transparency dashboard (https://transparency.flashbots.net/) for Q1 2023, which includes useful fields including the proposer's ETH reward, whether the validator used the MEV-boost Flashbots relay, the block number, the Ethereum network gas price, and more.\n",
    "\n",
    "We define **realized extractable value** as the difference between the block proposer's ETH balance before and after the block execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have lists of MEV-botted transactions from Q1 2023 (courtesy of [MEV-inspect](https://github.com/flashbots/mev-inspect-py)), which are strategies that MEV bots take advantage of whether by pure revenue profit or order optimization (OO) (see [Flash Boys 2.0](https://arxiv.org/abs/1904.05234)). These transaction lists include liquidations, arbitrages, sandwiches, and sandwiched swaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add useful predictors for our model, we will count how many of each transaction type is in each block, extract the hour of the day that the block was mined, and derive and aggregate some predictors from the gas fee attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "blocks_df = pd.read_csv('block_data_flashbots_dashboard_q1.csv')\n",
    "sandwiches_df = pd.read_csv('sandwiches.csv')\n",
    "liquidations_df = pd.read_csv('liquidations.csv')\n",
    "sandwiched_swaps_df = pd.read_csv('sandwiched_swaps.csv')\n",
    "arbitrages_df = pd.read_csv('arbitrages.csv')\n",
    "\n",
    "# Count the number of transactions of each transaction type for each block number\n",
    "sandwiches_count = sandwiches_df.groupby('block_number').size().reset_index(name='sandwiches_count')\n",
    "liquidations_count = liquidations_df.groupby('block_number').size().reset_index(name='liquidations_count')\n",
    "sandwiched_swaps_count = sandwiched_swaps_df.groupby('block_number').size().reset_index(name='sandwiched_swaps_count')\n",
    "arbitrages_count = arbitrages_df.groupby('block_number').size().reset_index(name='arbitrages_count')\n",
    "\n",
    "# Merge the count back into the blocks DataFrame\n",
    "blocks_df = blocks_df.merge(sandwiches_count, on='block_number', how='left')\n",
    "blocks_df = blocks_df.merge(liquidations_count, on='block_number', how='left')\n",
    "blocks_df = blocks_df.merge(sandwiched_swaps_count, on='block_number', how='left')\n",
    "blocks_df = blocks_df.merge(arbitrages_count, on='block_number', how='left')\n",
    "\n",
    "# Replace NaN with 0 in the count columns\n",
    "blocks_df['sandwiches_count'] = blocks_df['sandwiches_count'].fillna(0).astype(int)\n",
    "blocks_df['liquidations_count'] = blocks_df['liquidations_count'].fillna(0).astype(int)\n",
    "blocks_df['sandwiched_swaps_count'] = blocks_df['sandwiched_swaps_count'].fillna(0).astype(int)\n",
    "blocks_df['arbitrages_count'] = blocks_df['arbitrages_count'].fillna(0).astype(int)\n",
    "\n",
    "# Convert the 'block_timestamp' column to datetime and extract the hour\n",
    "blocks_df['hour_of_day'] = blocks_df['block_timestamp'].apply(\n",
    "    lambda x: datetime.utcfromtimestamp(x).hour\n",
    ")\n",
    "\n",
    "## Add some new potential predictors & analysis variables\n",
    "\n",
    "# How much of the block gas limit was utilized. Can be a proxy for network congestion during the time the block was mined.\n",
    "# Ideally the target should be 15 million gas used out of 30 million, and the base fee fluctuates accordingly (EIP 1559)\n",
    "blocks_df['block_fullness'] = blocks_df['gas_used'] / 30000000\n",
    "\n",
    "# Although we don't have the priority fee/tip, we can use this as a proxy for the total gas fees paid in the block\n",
    "blocks_df['total_gas_fees'] = blocks_df['gas_used'] * blocks_df['base_fee_per_gas_in_eth']\n",
    "\n",
    "# Change in base fee from one block to another indicates a trend in network congestion\n",
    "blocks_df['base_fee_change'] = blocks_df['base_fee_per_gas_in_eth'].diff()\n",
    "blocks_df['base_fee_change_percentage'] = (blocks_df['base_fee_change'] / blocks_df['base_fee_per_gas_in_eth'].shift()) * 100\n",
    "blocks_df.drop(columns=['base_fee_change'], inplace=True)\n",
    "\n",
    "# Let's see if this indicator means much\n",
    "blocks_df['network_demand'] = blocks_df['block_fullness'] * blocks_df['base_fee_change_percentage']\n",
    "\n",
    "# Handle cases where the previous base fee is zero\n",
    "blocks_df['network_demand'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean columns to numeric\n",
    "blocks_df['validator_is_registered_with_relay'] = blocks_df['validator_is_registered_with_relay'].astype(int)\n",
    "blocks_df['is_fb_builder'] = blocks_df['is_fb_builder'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame\n",
    "blocks_df.to_csv('block_data_ready.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns we won't use in analysis and save to a cleaned csv\n",
    "blocks_df.drop(columns=['block_number', 'block_hash', 'block_timestamp', 'header_fee_recipient', 'validator_fee_recipient', 'header_fee_recipient_balance_change_in_eth', 'validator_fee_recipient_balance_change_in_eth', 'gas_limit', 'extra_data', 'block_origin', 'builder'], inplace=True)\n",
    "\n",
    "# Save the cleaned DataFrame\n",
    "blocks_df.to_csv('block_data_ready_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
